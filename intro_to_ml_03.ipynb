{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "structured-fundamentals",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning<br><br>Day 03:<br>Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-horror",
   "metadata": {},
   "source": [
    "<center>Dr. William Mattingly<br>\n",
    "TAP Institute with JSTOR</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-palestine",
   "metadata": {},
   "source": [
    "1) What is text classification?<br>\n",
    "2) When should I use text classification?<br>\n",
    "3) spaCy's Text Classification Pipeline<br>\n",
    "4) Resources for future exploration of ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-carry",
   "metadata": {},
   "source": [
    "## Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-rider",
   "metadata": {},
   "source": [
    "This notebook will introduce the reader to more complex elements of machine learning through text classification. It will introduce the reader to new key terms, such as prediction, generalization, and accuracy metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-duncan",
   "metadata": {},
   "source": [
    "## Part One - Introduction to Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-friendly",
   "metadata": {},
   "source": [
    "In the last notebook, we engaged in a form of unsupervised learning. We allowed a system to take unstructured data and assign 20 categories to it. In this notebook, we will explore a different method of machine learning known as supervised learning. As noted in notebook 1, supervised learning is when we know the structure of our data. We have labels that correspond to that data and we leverage that knowledge to train a computer system to assign the same labels to similar unknown data. In NLP, text classification is a form of supervised learning.\n",
    "\n",
    "Classification tasks fall into roughly three categories:\n",
    "\n",
    "1) binary classification<br>\n",
    "2) multiclass classification<br>\n",
    "3) multilabel classification\n",
    "\n",
    "The differences will not be explored in great detail here as we will be dealing primarily with binary text classification. You should, however, be familiar with these three categories as you will choose different approaches to solve different problems.\n",
    "\n",
    "<b>Binary classification</b> is when a model has the ability to choose between two labels, a 0 and a 1. These numbers stand for a specific label. If we were to create a positive/negative review classifier (a common introducutory ML task), then 0 could be negative and 1 could be positive. After training, the model will see the entire world as either being positive or negative and when it encounters a new text, it will assign a float, or floating number (decimal) to that text. This is known as a <b>prediction</b>. The closer this prediction is to 0 or 1 indicates the degree to which the text at hand is positive or negative.\n",
    "\n",
    "<b>Multiclass classification</b> is when a model is designend to handle multiple potential labels. If we are trying to determine if a piece of text is a letter, movie review, or tax form, wew will have three potential labels (letter, movie_review, tax_form). The model will make a prediction based on its experiences during training to determine which of the texts it falls under. In multiclass classification, there can be only one label.\n",
    "\n",
    "<b>Multilabel classification</b> is like multiclass classification, except a text can have multiple labels. This is useful if you expect there to be multiple potential labels for texts in your corpus. Imagien if you have a text that is a letter in nature, but deals partially about a movie that the writer saw a few days earlier. A prediction of letter would be accurate as would movie_review, but a multiclass classification model cannot make these nuances known. A multilabel classification model can. Its output will look somewhat similar to a binary classification model for each potential label, so it may be (letter: 0.5030030, movie_review: 0.4020039, tax_form: 0.00002). This output captures the degree to which the text fits the form of a letter, but deals with the subject of a movie.\n",
    "\n",
    "The selection of prediction type affects the activation function used in the final layer of a neural network. An <b>activation function</b> is an output node in a neural network that determins the prediction. It is beyond the scope of these notebooks to cover this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-optics",
   "metadata": {},
   "source": [
    "## Part Two - When to Use Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-toronto",
   "metadata": {},
   "source": [
    "Text classification should be used when you either have access to a dataset with labels or intend to cultivate a dataset with labels. In my experience, text classification tends to achieve better results with texts that are longer (500+words)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-airplane",
   "metadata": {},
   "source": [
    "## Part Three - How to Collate Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-petite",
   "metadata": {},
   "source": [
    "For the digitial humanities, one of the largest problems is access to data. Unlike other industries and disciplines, the reliance on data came late to the humanities. As a result, few well-cultivated datasets exist. This means that the humanist who wishes to apply machine learning to their research, must not only be able to do so, but must also be familiar with how to collate good training data.\n",
    "\n",
    "In the last notebook, we used an off-the-shelf dataset. In real life, you will never have such a resource. There is no collection of labeled data for 13th century French literature (at least I don't think there is). For this reason, this notebook will spend the majority of the time collating a dataset from scratch for text classification.\n",
    "\n",
    "There are two main approaches to collating a good dataset.\n",
    "1) Manual annotation<br>\n",
    "2) Rules-Based annotation with manual validation<br>\n",
    "\n",
    "Manual annotations offer a guarantee that the dataset is 100% accurate. It is often good to have a <b>domain expert</b> do the annotations or validate them to ensure its accuracy. To produce a good binary classification model, one will need 200-500 samples minimum for each label. With harder classification problems, you will find that you need more.\n",
    "\n",
    "In some circumstances, it is infeasible, unrealistic, or too expensive to gather that much training data. Think of a 50-class classification model. That would require someone to manually annotate around 50,000 texts. In these scenarios, the practitioner can apply several tricks to rapidly cultivate a training set through a series of rules. The training set should then be manually validated by an expert. This approach is particularly useful if you do not know if a machine learning approach is even possible for the question you are asking.\n",
    "\n",
    "Because this is a short notebook, let's apply the latter and avoid having a content expert validate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-church",
   "metadata": {},
   "source": [
    "## Part Four - Introduction to spaCy's Text Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-flesh",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-smoke",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "metric-advice",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "radical-auckland",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-things",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "honey-marathon",
   "metadata": {},
   "source": [
    "## Resources for Further work with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-munich",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
